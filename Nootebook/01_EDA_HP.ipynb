{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('../Data/train.csv')\n",
    "test_df = pd.read_csv('../Data/test.csv')\n",
    "submission_df = pd.read_csv('../Data/sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# understanding and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train shape: {train_df.shape}\")\n",
    "\n",
    "print(f\"Data Types : {train_df.info()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_values_tarin = train_df.isnull().sum().sort_values(ascending=False)\n",
    "missing_values_tarin[missing_values_tarin>0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df , test_df]:\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "         df[col]=df[col].fillna(\"None\")\n",
    "        else:\n",
    "           df[col] = df[col].fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from autoviz.AutoViz_Class import AutoViz_Class\n",
    "\n",
    "# AV = AutoViz_Class()\n",
    "\n",
    "# av_report = AV.AutoViz(\n",
    "#     filename=\"\",  # Leave blank\n",
    "#     dfte=train_df,\n",
    "#     depVar=\"SalePrice\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#1.  Distrubtion of sales price\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(train_df['SalePrice'], kde=True, color='green')\n",
    "plt.title(\"Distribution of SalePrice\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Skewness:\", train_df['SalePrice'].skew())\n",
    "print(\"Kurtosis:\", train_df['SalePrice'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical columns only\n",
    "numeric_df = train_df.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Correlation with SalePrice\n",
    "correlation = numeric_df.corr()\n",
    "top_corr = correlation['SalePrice'].sort_values(ascending=False).head(15)\n",
    "\n",
    "# Heatmap of top correlated features\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(numeric_df[top_corr.index].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Top Correlated Features with SalePrice\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: OverallQual vs SalePrice\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='OverallQual', y='SalePrice', data=train_df)\n",
    "plt.title(\"Overall Quality vs SalePrice\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['GrLivArea', 'TotalBsmtSF', 'GarageCars', 'YearBuilt']\n",
    "for col in features:\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.scatterplot(data=train_df, x=col, y='SalePrice')\n",
    "    plt.title(f\"{col} vs SalePrice\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Neighborhood vs SalePrice\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.boxplot(x='Neighborhood', y='SalePrice', data=train_df)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Neighborhood vs SalePrice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#polting all the numerical feature \n",
    "df_num = train_df.select_dtypes(include = ['float64', 'int64'])\n",
    "\n",
    "df_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "#   Feature Engineering Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Separate target and drop from train\n",
    "train_labels = train_df['SalePrice']\n",
    "train_df = train_df.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# STEP 2: Combine train and test data\n",
    "full_df = pd.concat([train_df, test_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "# STEP 3: Drop 'Id' if present\n",
    "if 'Id' in full_df.columns:\n",
    "    full_df.drop('Id', axis=1, inplace=True)\n",
    "\n",
    "# STEP 4: Create new features\n",
    "full_df['TotalSF'] = full_df['TotalBsmtSF'] + full_df['1stFlrSF'] + full_df['2ndFlrSF']\n",
    "full_df['HouseAge'] = full_df['YrSold'] - full_df['YearBuilt']\n",
    "full_df['RemodAge'] = full_df['YrSold'] - full_df['YearRemodAdd']\n",
    "full_df['GarageAge'] = full_df['YrSold'] - full_df['GarageYrBlt']\n",
    "full_df['TotalBath'] = (full_df['FullBath'] + 0.5 * full_df['HalfBath'] +\n",
    "                        full_df['BsmtFullBath'] + 0.5 * full_df['BsmtHalfBath'])\n",
    "full_df['TotalPorchSF'] = (full_df['OpenPorchSF'] + full_df['EnclosedPorch'] +\n",
    "                           full_df['3SsnPorch'] + full_df['ScreenPorch'])\n",
    "full_df['OverallGrade'] = full_df['OverallQual'] * full_df['OverallCond']\n",
    "\n",
    "# If 'GarageQual' is already filled with string 'None', map to numbers\n",
    "garage_qual_mapping = {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n",
    "if 'GarageQual' in full_df.columns:\n",
    "    full_df['GarageScore'] = full_df['GarageArea'] * full_df['GarageQual'].map(garage_qual_mapping).fillna(0)\n",
    "else:\n",
    "    full_df['GarageScore'] = 0\n",
    "\n",
    "# STEP 5: One-hot encoding of categorical features\n",
    "full_df = pd.get_dummies(full_df, drop_first=True)\n",
    "\n",
    "# STEP 6: Split back into train and test\n",
    "X_train = full_df.iloc[:len(train_labels), :]\n",
    "X_test = full_df.iloc[len(train_labels):, :]\n",
    "y_train = train_labels\n",
    "\n",
    "print(\"âœ… Feature engineering completed.\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Log-transform the target\n",
    "y_train_log = np.log1p(y_train)  # log(1 + SalePrice)\n",
    "\n",
    "# Initialize model\n",
    "lr = LinearRegression()\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Cross-validation to evaluate performance\n",
    "scores = cross_val_score(lr, X_train, y_train, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(\"Linear Regression CV RMSE:\", -scores.mean())\n",
    "\n",
    "# Fit the model on the full training set\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "preds_lr = lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'Id': test_df['Id'],   # if you kept Id somewhere\n",
    "    'SalePrice': preds_lr\n",
    "})\n",
    "submission.to_csv(\"../Output/submission_linear.csv\", index=False)\n",
    "print(\"ðŸ“„ submission_linear.csv created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Cross-validation RMSE\n",
    "scores = cross_val_score(rf, X_train, y_train, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(\"Random Forest CV RMSE:\", -scores.mean())\n",
    "\n",
    "# Fit and predict\n",
    "rf.fit(X_train, y_train)\n",
    "preds_rf = rf.predict(X_test)\n",
    "\n",
    "# Save submission\n",
    "submission_rf = pd.DataFrame({\n",
    "    'Id': test_df['Id'],\n",
    "    'SalePrice': preds_rf\n",
    "})\n",
    "submission_rf.to_csv(\"../Output/submission_random_forest.csv\", index=False)\n",
    "print(\"ðŸ“„ submission_random_forest.csv created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(n_estimators=100, learning_rate=0.05, max_depth=3, random_state=42)\n",
    "scores = cross_val_score(xgb, X_train, y_train_log, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(\"XGBoost (log target) CV RMSE:\", -scores.mean())\n",
    "\n",
    "# Fit and predict\n",
    "xgb.fit(X_train, y_train_log)\n",
    "preds_xgb = np.expm1(xgb.predict(X_test))\n",
    "\n",
    "# Submission\n",
    "submission_xgb = pd.DataFrame({\n",
    "    'Id': test_df['Id'],\n",
    "    'SalePrice': preds_xgb\n",
    "})\n",
    "submission_xgb.to_csv(\"../Output/submission_xgboost.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Log-transform target\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "model = XGBRegressor(n_estimators=500, learning_rate=0.05, max_depth=3, random_state=42)\n",
    "\n",
    "# Cross-validation score\n",
    "scores = cross_val_score(model, X, y_log, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "print(\"XGBoost CV RMSE:\", -np.mean(scores))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
